{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kshape_(210307).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl-l50VKsiGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55d93b4-77a4-4bf2-bc3e-6e1b40a7e0de"
      },
      "source": [
        "!pip install tslearn\r\n",
        "\r\n",
        "import os\r\n",
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "import keras.backend as K\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.cm as cm \r\n",
        "import pylab as plt\r\n",
        "import pandas as pd\r\n",
        "import glob\r\n",
        "import math\r\n",
        "import cv2\r\n",
        "import pickle\r\n",
        "import umap\r\n",
        "\r\n",
        "from fastdtw import fastdtw\r\n",
        "from scipy.spatial.distance import euclidean, cityblock\r\n",
        "from math import cos, pi\r\n",
        "\r\n",
        "from matplotlib import cm\r\n",
        "from sklearn import manifold\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.metrics import silhouette_score\r\n",
        "from sklearn.metrics import silhouette_samples\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.utils.linear_assignment_ import linear_assignment\r\n",
        "\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.cluster import DBSCAN\r\n",
        "\r\n",
        "from tslearn.clustering import KShape\r\n",
        "\r\n",
        "from math import sqrt\r\n",
        "from scipy.cluster import vq\r\n",
        "from scipy.spatial.distance import cdist\r\n",
        "from sklearn.datasets.samples_generator import make_blobs\r\n",
        "\r\n",
        "from tensorflow.python.keras.backend import eager_learning_phase_scope\r\n",
        "from keras.engine.topology import Layer\r\n",
        "from tensorflow.keras.models import Sequential, Model\r\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Flatten, BatchNormalization, Reshape, LeakyReLU,Conv1D, UpSampling1D, MaxPooling1D, Conv1DTranspose, ELU, Dropout,MaxPooling2D, UpSampling2D, concatenate,Activation\r\n",
        "from keras.layers import Input\r\n",
        "from keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "from keras.preprocessing.image import load_img, array_to_img, img_to_array, ImageDataGenerator\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "\r\n",
        "np.set_printoptions(threshold=np.inf) #...없이 출력하기"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tslearn in /usr/local/lib/python3.7/dist-packages (0.5.0.5)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tslearn) (0.29.22)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tslearn) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from tslearn) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from tslearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from tslearn) (0.51.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tslearn) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->tslearn) (54.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->tslearn) (0.34.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW7ZVTviKTWb"
      },
      "source": [
        "# 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH-iHAr08KFl"
      },
      "source": [
        "Data Proprocessing(0) : CSV로부터 DATA 입력받기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgnNbxjAVbIF"
      },
      "source": [
        "# 데이터 입력 함수\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "path : csv 파일의 경로\r\n",
        "column : 데이터를 나타내는 칼럼명\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def align_timeseries_dataset(path,column):\r\n",
        "  \r\n",
        "  input_csv = pd.read_csv(path,engine='python')\r\n",
        "  input_csv = input_csv.astype({column:'float32'})\r\n",
        "  \r\n",
        "  dataset = input_csv[column]\r\n",
        "  \r\n",
        "  return np.array(dataset)\r\n",
        "\r\n"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL7h-PryA75d"
      },
      "source": [
        "Data preprocessing function(1) - 시계열 데이터 길이 조절(truncation, padding, sliding window, DTW 등)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0N-I9vfBEhP"
      },
      "source": [
        "# 데이터 자르기 함수\r\n",
        "\r\n",
        "def data_truncation(dataset):\r\n",
        "  \r\n",
        "  return_dataset = []\r\n",
        "  max_size = 0\r\n",
        "  min_size = 999999\r\n",
        "\r\n",
        "  for i in range(len(dataset)):\r\n",
        "    if dataset[i].size < min_size:\r\n",
        "      min_size=dataset[i].size\r\n",
        "\r\n",
        "  for i in range(len(dataset)):\r\n",
        "    if dataset[i].size > min_size:\r\n",
        "      return_dataset.append(dataset[i][:min_size])\r\n",
        "    else:\r\n",
        "      return_dataset.append(dataset[i])\r\n",
        "\r\n",
        "  return np.array(return_dataset)\r\n",
        "\r\n",
        "# 데이터 패딩 함수\r\n",
        "\r\n",
        "def data_padding(dataset):\r\n",
        "\r\n",
        "  return_dataset = []\r\n",
        "  max_size = 0\r\n",
        "  min_size = 999999\r\n",
        "\r\n",
        "  for i in range(len(dataset)):\r\n",
        "    if dataset[i].size > max_size:\r\n",
        "      max_size=dataset[i].size\r\n",
        "\r\n",
        "  for i in range(len(dataset)):\r\n",
        "    if dataset[i].size < max_size:\r\n",
        "      return_dataset.append(np.pad(dataset[i], (0,max_size-dataset[i].size), 'constant', constant_values=0))\r\n",
        "    else:\r\n",
        "      return_dataset.append(dataset[i])\r\n",
        "\r\n",
        "  return np.array(return_dataset)\r\n",
        "\r\n",
        "# Sliding window 함수\r\n",
        "\r\n",
        "def sliding_window(dataset, window_size = 10 , shift_size = 1):\r\n",
        "\r\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(dataset)\r\n",
        "  dataset = dataset.window(window_size, shift=shift_size, drop_remainder=True)\r\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size))\r\n",
        "  return_dataset = list()\r\n",
        "\r\n",
        "  for window in dataset:\r\n",
        "    return_dataset.append(window.numpy())\r\n",
        "  return_dataset = np.array(return_dataset)\r\n",
        "\r\n",
        "  return return_dataset\r\n",
        "\r\n",
        "# DTW 유사도를 통한 시계열 데이터 확장 함수 (작은 길이를 큰 길이로 맞춤)\r\n",
        "\r\n",
        "\r\n",
        "def DTW_resize_algorithm(long_ts_data, short_ts_data):\r\n",
        "\r\n",
        "  if len(long_ts_data) == len(short_ts_data):\r\n",
        "    return np.array(short_ts_data), np.array([0]*len(short_ts_data))\r\n",
        "\r\n",
        "  step = 0\r\n",
        "  similarity_degree_path = [0]*len(long_ts_data)\r\n",
        "  long_ts_data = np.array(long_ts_data)\r\n",
        "  short_ts_data = np.array(short_ts_data)\r\n",
        "\r\n",
        "  path_coordinates = fastdtw(short_ts_data, long_ts_data)[1]\r\n",
        "\r\n",
        "  for i in range(len(similarity_degree_path)):\r\n",
        "\r\n",
        "    similarity_degree_path[i] = (long_ts_data[path_coordinates[step][1]]-short_ts_data[path_coordinates[step][0]])\r\n",
        "    \r\n",
        "    for j in range(step+1,len(path_coordinates)):\r\n",
        "\r\n",
        "      if path_coordinates[step][1] == path_coordinates[j][1]:\r\n",
        "        similarity_degree_path[i] = similarity_degree_path[i] + (long_ts_data[path_coordinates[j][1]]-short_ts_data[path_coordinates[j][0]])\r\n",
        "        step=j\r\n",
        "        continue\r\n",
        "\r\n",
        "      else:\r\n",
        "        step+=1\r\n",
        "        break\r\n",
        "        \r\n",
        "  resize_ts_data = (long_ts_data - similarity_degree_path)\r\n",
        "\r\n",
        "  return np.array(resize_ts_data), np.array(similarity_degree_path)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhsX9jUXAybS"
      },
      "source": [
        "Data preprocessing function(2) - 데이터 정규화 or 일반화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXJK_ZNG8s53"
      },
      "source": [
        "# Min-Max Normalization: 모든 feature들의 스케일이 동일하지만, 이상치(outlier)를 잘 처리하지 못한다.\r\n",
        "\r\n",
        "def min_max_normalize(lst):\r\n",
        "    normalized = []\r\n",
        "    \r\n",
        "    min_value = min(lst)\r\n",
        "    max_value = max(lst)\r\n",
        "\r\n",
        "    for value in lst:\r\n",
        "        normalized_num = (value - min_value) / (max_value -min_value)\r\n",
        "        normalized.append(normalized_num)\r\n",
        "    \r\n",
        "    return normalized\r\n",
        "\r\n",
        "# Z-Score Normalization : 이상치(outlier)를 잘 처리하지만, 정확히 동일한 척도로 정규화 된 데이터를 생성하지는 않는다.\r\n",
        "\r\n",
        "def z_score_normalize(lst):\r\n",
        "    normalized = []\r\n",
        "\r\n",
        "    mean_value = np.mean(lst)\r\n",
        "    std_value = np.std(lst)\r\n",
        "    \r\n",
        "    for value in lst:\r\n",
        "        normalized_num = (value - mean_value) / std_value\r\n",
        "        normalized.append(normalized_num)\r\n",
        "    return normalized"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZGjqHF7Anzk"
      },
      "source": [
        "Data preprocessing function(3) - 잠재 벡터 추출(UMAP, 이미지화 등)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PL1tD8BBiKF"
      },
      "source": [
        "\"\"\"\r\n",
        "RP 알고리즘\r\n",
        "\r\n",
        "serialize_vector : 시계열 데이터 value vector\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def RP_algorithm(serialize_vector):\r\n",
        "\r\n",
        "    N = serialize_vector.size\r\n",
        "    S = np.repeat(serialize_vector[None,:],N,axis=0)\r\n",
        "    Z = np.abs(S-S.T)\r\n",
        "    Z/=Z.max()\r\n",
        "    Z*=255\r\n",
        "    Z = Z.astype('uint8')\r\n",
        "    Z = np.array(Z)\r\n",
        "    return Z\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "GAF 알고리즘 \r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def tabulate(x, y, f):\r\n",
        "    \"\"\"Return a table of f(x, y). Useful for the Gram-like operations.\"\"\"\r\n",
        "    return np.vectorize(f)(*np.meshgrid(x, y, sparse=True))\r\n",
        "def cos_sum(a, b):\r\n",
        "    \"\"\"To work with tabulate.\"\"\"\r\n",
        "    return(math.cos(a+b))\r\n",
        "\r\n",
        "class GAF_algorithm:\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        pass\r\n",
        "    def __call__(self, serie):\r\n",
        "        \"\"\"Compute the Gramian Angular Field of an image\"\"\"\r\n",
        "        # Min-Max scaling\r\n",
        "        min_ = np.amin(serie)\r\n",
        "        max_ = np.amax(serie)\r\n",
        "        scaled_serie = (2*serie - max_ - min_)/(max_ - min_)\r\n",
        "\r\n",
        "        # Floating point inaccuracy!\r\n",
        "        scaled_serie = np.where(scaled_serie >= 1., 1., scaled_serie)\r\n",
        "        scaled_serie = np.where(scaled_serie <= -1., -1., scaled_serie)\r\n",
        "\r\n",
        "        # Polar encoding\r\n",
        "        phi = np.arccos(scaled_serie)\r\n",
        "        # Note! The computation of r is not necessary\r\n",
        "        r = np.linspace(0, 1, len(scaled_serie))\r\n",
        "\r\n",
        "        # GAF Computation (every term of the matrix)\r\n",
        "        gaf = tabulate(phi, phi, cos_sum)\r\n",
        "\r\n",
        "        return(gaf, phi, r, scaled_serie)\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "image_vector : 변경하고자 하는 이미지 리스\r\n",
        "img_size : 변경하고자 하는 이미지 크기\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def resize_img(image_vector_list, img_size):\r\n",
        "\r\n",
        "  image_list = []\r\n",
        "  for i in range(len(image_vector_list)):\r\n",
        "  \r\n",
        "    img = cv2.resize(image_vector_list[i],(img_size,img_size),interpolation = cv2.INTER_AREA)\r\n",
        "    img = img.astype('uint8')\r\n",
        "    image_list.append(img)\r\n",
        "\r\n",
        "  image_list = np.array(image_list)\r\n",
        "\r\n",
        "  return image_list"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB_53SpltvQE"
      },
      "source": [
        "# Auto_Encoder 함수\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "dataset : (n,) shape의 데이터\r\n",
        "LEARNING_LATE : 러닝레이트\r\n",
        "BATCH_SIZE : 배치사이즈\r\n",
        "EPOCHS : 에폭\r\n",
        "TEST_SIZE : traing에서 뽑아낼 test 사이즈(default = 100)\r\n",
        "IMG_SIZE : 이미지사이즈(default = 64)\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def embedding_AE(dataset, LEARNING_LATE,BATCH_SIZE,EPOCHS,TEST_SIZE=100,IMG_SIZE=64):\r\n",
        "  \r\n",
        "  np.random.seed(1)\r\n",
        "  tf.random.set_seed(1)\r\n",
        "\r\n",
        "  latent_dim = 2\r\n",
        "\r\n",
        "  # 시계열데이터 이미지화\r\n",
        "\r\n",
        "  dataset_img = []\r\n",
        "\r\n",
        "  for i in range(len(dataset)):\r\n",
        "    dataset_img.append(RP_algorithm(dataset[i]))\r\n",
        "\r\n",
        "  dataset_class_img = resize_img(dataset_img,IMG_SIZE)\r\n",
        "  dataset_class_img = np.array(dataset_class_img)\r\n",
        "\r\n",
        "  dataset_image = dataset_class_img.reshape(len(dataset),IMG_SIZE,IMG_SIZE)\r\n",
        "\r\n",
        "  # Image -> train / test로 나누기\r\n",
        "\r\n",
        "  train = dataset_image\r\n",
        "  np.random.shuffle(train)\r\n",
        "\r\n",
        "  train = train.reshape(-1,IMG_SIZE,IMG_SIZE,1)\r\n",
        "\r\n",
        "  test = train[len(train)-TEST_SIZE:]\r\n",
        "  train = train[:len(train)-TEST_SIZE]  \r\n",
        "\r\n",
        "  # 데이터 정규화\r\n",
        "\r\n",
        "  train = train/dataset_image.max()\r\n",
        "  test = test/dataset_image.max()\r\n",
        "\r\n",
        "  # 체크포인트 설정\r\n",
        "\r\n",
        "  ae_checkpoint_path = 'AE.ckpt'\r\n",
        "  ae_checkpoint_dir = os.path.dirname(ae_checkpoint_path)\r\n",
        "\r\n",
        "  ae_callback_early = keras.callbacks.EarlyStopping(\r\n",
        "            monitor='loss',\r\n",
        "            min_delta=0,\r\n",
        "            patience=50,\r\n",
        "            verbose=0,\r\n",
        "            mode='auto'\r\n",
        "  )\r\n",
        "\r\n",
        "  ae_callback_best = keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=ae_checkpoint_path,\r\n",
        "    monitor='loss',\r\n",
        "    verbose=0,\r\n",
        "    save_best_only=True,\r\n",
        "    save_weights_only=True,\r\n",
        "    mode='min',\r\n",
        "    save_freq=1\r\n",
        "    )\r\n",
        "  \r\n",
        "  # AE Layer 설정\r\n",
        "\r\n",
        "  encoder_input = Input(shape=(IMG_SIZE,IMG_SIZE,1), name='input')\r\n",
        "\r\n",
        "  x = Conv2D(16, 3,strides=2, padding='same',activation='relu')(encoder_input)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  x = Conv2D(32, 3, strides=2, padding='same',activation='relu')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  x = Conv2D(64, 3, strides=2,padding='same',activation='relu')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  x = Flatten()(x)\r\n",
        "  units = x.shape[1]\r\n",
        "\r\n",
        "  # 2D 좌표로 표기하기 위하여 2를 출력값으로 지정\r\n",
        "  embed = Dense(latent_dim,name='embedded')(x)\r\n",
        "\r\n",
        "  x = Dense(units)(embed)\r\n",
        "  x = Reshape((8, 8, 64))(x)\r\n",
        "\r\n",
        "  x = Conv2DTranspose(64, 3, strides=1, padding='same',activation='relu')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  x = Conv2DTranspose(32, 3, strides=2, padding='same',activation='relu')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  x = Conv2DTranspose(16, 3, strides=2, padding='same',activation='relu')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  decoder_outputs = Conv2DTranspose(1, (3,3), strides=2, padding='same', activation='sigmoid',name='output')(x)\r\n",
        "\r\n",
        "  # 오토인코더 실행\r\n",
        "\r\n",
        "  autoencoder = Model(encoder_input, decoder_outputs)\r\n",
        "  autoencoder.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_LATE), loss=tf.keras.losses.MeanSquaredError())\r\n",
        "\r\n",
        "  hist = autoencoder.fit(train, train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data =(test,test),shuffle=True,callbacks=[ae_callback_early,ae_callback_best])\r\n",
        "\r\n",
        "  # 이미지 그리기\r\n",
        "\r\n",
        "  decoded_images = autoencoder.predict(test)\r\n",
        "\r\n",
        "  draw_image_data(test,\"Original Image\",IMG_SIZE)\r\n",
        "  draw_image_data(decoded_images,\"Reproduction Image\",IMG_SIZE)\r\n",
        "\r\n",
        "  # 인코딩된 잠재 벡터 \r\n",
        "\r\n",
        "  get_embedded = K.function([autoencoder.get_layer('input').input],\r\n",
        "                                  [autoencoder.get_layer('embedded').output])\r\n",
        "  \r\n",
        "  dataset_dimension = np.vstack(get_embedded([dataset_image]))\r\n",
        "  dataset_dimension_data = np.vstack([dataset_dimension])\r\n",
        "  dataset_dimension_data = dataset_dimension_data.reshape(-1,latent_dim)\r\n",
        "\r\n",
        "  return dataset_dimension_data"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFvCxp4AtzEl"
      },
      "source": [
        "# UMAP 함수\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "n_components : 축소하고자 하는 차원수\r\n",
        "n_neighbors : 작을수록 locality를 잘 나타내고, 커질수록 global structure를 잘 나타냄\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def embedding_UMAP(dataset, components=2, neighbors=50):\r\n",
        "  reducer = umap.UMAP(n_components=2,n_neighbors=50,init='random',random_state=0)\r\n",
        "  embedding = reducer.fit_transform(dataset)\r\n",
        "  return embedding"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aasnkAwgwndv"
      },
      "source": [
        "# PCA 함수\r\n",
        "\"\"\"\r\n",
        "n_component : 주성분 분석 개수\r\n",
        "반환값 : PCA 실행 결과 \r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def embedding_PCA(dataset, n_component=2):\r\n",
        "  pca = PCA(n_components=n_component)\r\n",
        "  pca.fit(dataset)\r\n",
        "  dataset_pca = pca.transform(dataset)\r\n",
        "  #print(pca.explained_variance_ratio_)\r\n",
        "  return dataset_pca"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH_8GLJhwAtS"
      },
      "source": [
        "Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x79WRrQYv_-m"
      },
      "source": [
        "# K-means 함수\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "dimension_data=잠재벡터\r\n",
        "MAX_CLUSTER_SIZE=최대 군집 개수\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def clustering_KMEANS(dimension_data,MAX_CLUSTER_SIZE = 10) : \r\n",
        "  #class_dimension_data=잠재벡터,num_cluster=최대 군집 개수\r\n",
        "\r\n",
        "  n_cluster_list = cal_Silhouette(dimension_data,MAX_CLUSTER_SIZE,5)\r\n",
        "  #best_cluster = n_cluster_list[0]\r\n",
        "\r\n",
        "  dimension_data = dimension_data.reshape(-1,2)\r\n",
        "\r\n",
        "  for center in n_cluster_list:\r\n",
        "    draw_cluster_and_center(dimension_data,center)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVsSgyx7H4R7"
      },
      "source": [
        "# K-shape 함수\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "timeseries_data=\r\n",
        "n_cluster=군집 수\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def clustering_KSHAPE(timeseries_data,n_cluster=2) : \r\n",
        "\r\n",
        "  ks = KShape(n_clusters=n_cluster)\r\n",
        "  cluster_found_kshape = ks.fit_predict(timeseries_data)\r\n",
        "\r\n",
        "  return cluster_found_kshape"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOpPAJQVw6op"
      },
      "source": [
        "# DBSCAN 함수 \r\n",
        "\"\"\"\r\n",
        "eps : 기준점으로부터의 거리\r\n",
        "min_samples : 반경 내의 점의 개수\r\n",
        "반환값 : dbscan 군집 결과\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def clsutering_DBSCAN(dataset,eps, min_samples):\r\n",
        "  dbscan = DBSCAN(eps = eps, min_samples= min_samples)\r\n",
        "  predict = dbscan.fit_predict(dataset)\r\n",
        "\r\n",
        "  max = predict.max()\r\n",
        "  \r\n",
        "  for i in range(len(dataset)):\r\n",
        "    if predict[i]== -1:\r\n",
        "      predict[i]= max+1\r\n",
        "      \r\n",
        "  return predict "
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mYGo3aOxMQs"
      },
      "source": [
        "# ISODATA 함수\r\n",
        "\r\n",
        "def initialize_parameters(parameters=None):\r\n",
        "  # 파라미터 값 지정하기\r\n",
        "    parameters = {} if not parameters else parameters\r\n",
        "\r\n",
        "    def safe_pull_value(parameters, key, default):\r\n",
        "        return parameters.get(key, default)\r\n",
        "\r\n",
        "    # 대략적으로 요구되는 군집 수 (실루엣 값 입력)\r\n",
        "    K = safe_pull_value(parameters, 'K', 7)\r\n",
        "\r\n",
        "    # 최대 Iteration 횟수\r\n",
        "    I = safe_pull_value(parameters, 'I', 100)\r\n",
        "\r\n",
        "    # maximum of number of pairs of clusters which can be merged : 결합될 수 있는 최대 군집 수\r\n",
        "    P = safe_pull_value(parameters, 'P', 2)\r\n",
        "\r\n",
        "    # 군집을 만드는 최소 표본의 개수\r\n",
        "    THETA_M = safe_pull_value(parameters, 'THETA_M', 20)\r\n",
        "    # threshold value for standard deviation (for split) Split을 위한 표준편차 (최대 분산 파라미터)\r\n",
        "    THETA_S = safe_pull_value(parameters, 'THETA_S', 1)\r\n",
        "    # threshold value for pairwise distances (for merge) Merge가 요구되는 최대 분리 거리\r\n",
        "    THETA_C = safe_pull_value(parameters, 'THETA_C', 5)\r\n",
        "\r\n",
        "    # Iteration 당 Cluster의 변화율\r\n",
        "    THETA_O = 0.05\r\n",
        "\r\n",
        "    # 클러스터 개수의 초기값 설정(random or K)\r\n",
        "    #k = np.random.randint(1, K)\r\n",
        "    k = safe_pull_value(parameters, 'k', K)\r\n",
        "\r\n",
        "    ret = locals()\r\n",
        "    ret.pop('safe_pull_value')\r\n",
        "    ret.pop('parameters')\r\n",
        "    # 지역변수를 전역변수로 올려주는 역할\r\n",
        "    globals().update(ret) \r\n",
        "\r\n",
        "\r\n",
        "def initial_clusters(img, k):\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    초기 클러스터 임의 설정\r\n",
        "    \"\"\"\r\n",
        "    np.random.shuffle(img)\r\n",
        "    centers = img[0:k]\r\n",
        "    \r\n",
        "    return centers\r\n",
        "\r\n",
        "def discard_clusters(img_class, centers, clusters_list):\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "      최소 표본을 만족하지 못한 cluster center 폐기\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    k = centers.shape[0]\r\n",
        "    to_delete = np.array([0])\r\n",
        "\r\n",
        "    for cluster in range(0, k):\r\n",
        "        indices = np.where(img_class == clusters_list[cluster])[0]\r\n",
        "        total_per_cluster = indices.size\r\n",
        "\r\n",
        "        if total_per_cluster <= THETA_M:\r\n",
        "            to_delete = np.append(to_delete, cluster)\r\n",
        "    if to_delete.size:\r\n",
        "        new_centers = np.delete(centers, to_delete, axis=0)\r\n",
        "        new_clusters_list = np.delete(clusters_list, to_delete)\r\n",
        "    else:\r\n",
        "        new_centers = centers\r\n",
        "        new_clusters_list = clusters_list\r\n",
        "\r\n",
        "    return new_centers, new_clusters_list\r\n",
        "\r\n",
        "\r\n",
        "def update_clusters(img, img_class, centers, clusters_list):\r\n",
        "    cluster = centers.shape[0]\r\n",
        "\r\n",
        "    for i in range(cluster):\r\n",
        "        indices = np.where(img_class == clusters_list[i])[0]\r\n",
        "        cluster_values = img[indices]\r\n",
        "        centers[i] = tf.reduce_mean(cluster_values, axis=0)\r\n",
        "\r\n",
        "    return centers\r\n",
        "\r\n",
        "def split_clusters(img, img_class, centers, clusters_list):\r\n",
        "    cluster = centers.shape[0]\r\n",
        "    varicance = []\r\n",
        "    #sigma = 10\r\n",
        "\r\n",
        "    for i in clusters_list:\r\n",
        "        indices = np.where(img_class == clusters_list[i])[0]\r\n",
        "        cluster_values = img[indices]\r\n",
        "        number = indices.size\r\n",
        "        varicance = np.var(cluster_values, axis=0)\r\n",
        "        var_max = varicance[np.argmax(varicance)]\r\n",
        "\r\n",
        "        if var_max > THETA_S and number > 2*THETA_M:\r\n",
        "            clusters_list = np.append(clusters_list, clusters_list.size)\r\n",
        "            a = np.zeros(centers.shape[1])\r\n",
        "            b = a + var_max\r\n",
        "            centers[i] = centers[i] - b\r\n",
        "            centers = np.append(centers, [centers[i] + b], axis=0)\r\n",
        "\r\n",
        "    return centers, clusters_list\r\n",
        "\r\n",
        "\r\n",
        "def merge_clusters(img_class, centers, clusters_list):\r\n",
        "    pair_dists = []\r\n",
        "    size = centers.shape[1]\r\n",
        "\r\n",
        "    for i in range(0, size):\r\n",
        "        for j in range(0, size):\r\n",
        "            if i > j:\r\n",
        "                d = sqrt(cdist([centers[i]], [centers[j]], metric= 'sqeuclidean'))\r\n",
        "                pair_dists.append((d, (i, j)))\r\n",
        "    first_p_elements = pair_dists[:P]\r\n",
        "    below_threshold = [(c1, c2) for d, (c1, c2) in first_p_elements if d < THETA_C]\r\n",
        "\r\n",
        "    if below_threshold:\r\n",
        "        k = centers.shape[1]\r\n",
        "        count_per_cluster = np.zeros(k)\r\n",
        "        # new clusters to add\r\n",
        "        to_add = np.array([]) \r\n",
        "        # clusters to delete\r\n",
        "        to_delete = np.array([])  \r\n",
        "\r\n",
        "        for cluster in range(0, k):\r\n",
        "            result = np.where(img_class == clusters_list[cluster])\r\n",
        "            indices = result[0]\r\n",
        "            count_per_cluster[cluster] = indices.size\r\n",
        "\r\n",
        "        for c1, c2 in below_threshold:\r\n",
        "            c1_count = float(count_per_cluster[c1])\r\n",
        "            c2_count = float(count_per_cluster[c2])\r\n",
        "            factor = 1.0 / (c1_count + c2_count)\r\n",
        "            weight_c1 = c1_count * centers[c1]\r\n",
        "            weight_c2 = c2_count * centers[c2]\r\n",
        "\r\n",
        "            value = factor * (weight_c1 + weight_c2)\r\n",
        "\r\n",
        "            to_add = np.append(to_add, value)\r\n",
        "            to_delete = np.append(to_delete, [c1, c2])\r\n",
        "\r\n",
        "            # delete old clusters and their indices from the availables array\r\n",
        "            centers = np.delete(centers, to_delete, axis=0)\r\n",
        "            clusters_list = np.delete(clusters_list, to_delete)\r\n",
        "\r\n",
        "            # generate new indices for the new clusters\r\n",
        "            # starting from the max index 'to_add.size' times\r\n",
        "            start = int(clusters_list.max())\r\n",
        "            end = to_add.size + start\r\n",
        "\r\n",
        "            centers = np.append(centers, to_add, axis=0)\r\n",
        "            clusters_list = np.append(clusters_list, range(start, end))\r\n",
        "            #centers, clusters_list = sort_arrays_by_first(centers, clusters_list)\r\n",
        "\r\n",
        "    return centers, clusters_list\r\n",
        "\r\n",
        "\r\n",
        "def clustering_ISODATA(dataset, parameters=None):\r\n",
        "    global K, I, P, THETA_M, THETA_S, THETA_C, THETA_O, k\r\n",
        "    initialize_parameters(parameters)\r\n",
        "    #clusters_list = np.arange(k)  # number of clusters availables\r\n",
        "    centers = initial_clusters(dataset, k)\r\n",
        "\r\n",
        "    for iter in range(0, I):\r\n",
        "        #last_centers = centers.copy()\r\n",
        "        # assing each of the samples to the closest cluster center\r\n",
        "        \r\n",
        "        k = centers.shape[0]\r\n",
        "        clusters_list = np.arange(k)\r\n",
        "        img_class, dists = vq.vq(dataset, centers)\r\n",
        "        centers, clusters_list = discard_clusters(img_class, centers, clusters_list)\r\n",
        "\r\n",
        "        k = centers.shape[0]\r\n",
        "        clusters_list = np.arange(k)\r\n",
        "        img_class, dists = vq.vq(dataset, centers)\r\n",
        "        centers = update_clusters(dataset, img_class, centers, clusters_list)\r\n",
        "        \r\n",
        "        k = centers.shape[0]\r\n",
        "        if k <= (K / 2.0):\r\n",
        "            centers, clusters_list = split_clusters(dataset, img_class,centers, clusters_list)\r\n",
        "        elif k > (K * 2.0):\r\n",
        "            centers, clusters_list = merge_clusters(img_class, centers,clusters_list)\r\n",
        "        else:\r\n",
        "            pass\r\n",
        "        img_class, dists = vq.vq(dataset, centers)\r\n",
        "\r\n",
        "    return img_class"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEcJyCStBSJr"
      },
      "source": [
        "기타 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n46OZjCcBy6M"
      },
      "source": [
        "# 실루엣 다이어그램 그리는 함수\r\n",
        "\r\n",
        "def plotSilhouette(X, y_km):\r\n",
        "    cluster_labels = np.unique(y_km)\r\n",
        "    n_clusters = cluster_labels.shape[0]\r\n",
        "    silhouette_vals = silhouette_samples(X, y_km, metric = 'euclidean')\r\n",
        "    y_ax_lower, y_ax_upper = 0, 0\r\n",
        "    yticks = []\r\n",
        "\r\n",
        "    for i, c in enumerate(cluster_labels):\r\n",
        "        c_silhouette_vals = silhouette_vals[y_km == c]\r\n",
        "        c_silhouette_vals.sort()\r\n",
        "        y_ax_upper += len(c_silhouette_vals)\r\n",
        "        color = cm.jet(i/n_clusters)\r\n",
        "\r\n",
        "        plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0,\r\n",
        "                edgecolor='none', color=color)\r\n",
        "        yticks.append((y_ax_lower + y_ax_upper)/2)\r\n",
        "        y_ax_lower += len(c_silhouette_vals)\r\n",
        "\r\n",
        "    silhoutte_avg = np.mean(silhouette_vals)\r\n",
        "    plt.axvline(silhoutte_avg, color = 'red', linestyle='--')\r\n",
        "    plt.yticks(yticks, cluster_labels+1)\r\n",
        "    plt.ylabel('K')\r\n",
        "    plt.xlabel('Silhouette value')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "#  실루엣 계수 계산 함수\r\n",
        "#  max_cluster_num : 최대 클러스터 개수(k)\r\n",
        "#  cluster_num : 추출할 실루엣 계수 높은 클러스터 개수\r\n",
        "\r\n",
        "def cal_Silhouette(data,max_cluster_num,cluster_num):\r\n",
        "  max = []\r\n",
        "\r\n",
        "  for i in range(2,max_cluster_num+1):\r\n",
        "    km=KMeans(n_clusters=i,random_state=10)\r\n",
        "    km_labels = km.fit_predict(data)\r\n",
        "    max.append([i,silhouette_score(data, km_labels)])\r\n",
        "    \r\n",
        "    max.sort(key=lambda x:x[1],reverse=True)\r\n",
        "  print(max)\r\n",
        "# 실루엣 계수 높은 상위 (clust_num)개만 추출해서 클러스터 개수 저장\r\n",
        "  n_cluster_list=[]\r\n",
        "\r\n",
        "  for i in max[0:cluster_num]:\r\n",
        "    n_cluster_list.append(i[0])\r\n",
        "\r\n",
        "  return n_cluster_list\r\n",
        "\r\n",
        "def draw_inertia_kshape(dimension_data,MAX_CLUSTER_SIZE=10):\r\n",
        "\r\n",
        "  distortions_kshape = []\r\n",
        "\r\n",
        "  for i in range(2,MAX_CLUSTER_SIZE+1):\r\n",
        "    \r\n",
        "    kshape = KShape(n_clusters=i, max_iter=100)\r\n",
        "    cluster_found = kshape.fit_predict(dimension_data)\r\n",
        "    distortions_kshape.append(kshape.inertia_)\r\n",
        "\r\n",
        "  plt.plot(range(2,MAX_CLUSTER_SIZE+1), distortions_kshape, marker='o')\r\n",
        "  plt.xlabel('Number of clusters')\r\n",
        "  plt.ylabel('Distortion')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "cluster_list 의 k 값으로 실루엣 다이어그램 작성 함수\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def draw_Silhouette_Diagram(data, n_cluster_list):\r\n",
        "  for i in range(len(n_cluster_list)):\r\n",
        "    print(\"Cluster 개수 : \",n_cluster_list[i])\r\n",
        "    \r\n",
        "    km=KMeans(n_clusters=n_cluster_list[i],random_state=10)\r\n",
        "    km_labels = km.fit_predict(data)\r\n",
        "    plotSilhouette(data,km_labels)\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "center : cluster center 수\r\n",
        "data : cluster data\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def draw_cluster_and_center(data,center):\r\n",
        "  Kmean=KMeans(n_clusters=center)\r\n",
        "  Kmean.fit(data)\r\n",
        "\r\n",
        "  plt.scatter(data[:,0],data[:,1],s=0.05,c=Kmean.labels_.astype(float))\r\n",
        "\r\n",
        "  print(\"Center 개수 : \",center)\r\n",
        "  for i in range(center):\r\n",
        "    plt.scatter(Kmean.cluster_centers_[i,0],Kmean.cluster_centers_[i,1],s=50,c='red',marker='s')\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4qXki0N8o9u"
      },
      "source": [
        "# 시계열 데이터 그리는 함수\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "dimenstion_data : 2차원의 데이터\r\n",
        "predict : 라벨 번호 list (정답)\r\n",
        "label : 라벨 이름 list\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "def draw_vector_data(dimenstion_data, predict=None,label=None):\r\n",
        "\r\n",
        "  plt.figure(figsize=(15,15))\r\n",
        "  plt.rc('legend', fontsize='20')\r\n",
        "\r\n",
        "  if predict is not None:\r\n",
        "\r\n",
        "    #n_clusters = set(predict)\r\n",
        "    #color = cm.rainbow(np.linspace(0, len(n_clusters), dimenstion_data.shape[0]))\r\n",
        "    \r\n",
        "    if label is None:\r\n",
        "      plt.scatter(dimenstion_data[:,0],dimenstion_data[:,1],s=30,c=predict)\r\n",
        "        \r\n",
        "    else : \r\n",
        "      plt.scatter(dimenstion_data[0],dimenstion_data[1],s=30,label=label,c=predict)\r\n",
        "\r\n",
        "  else:\r\n",
        "    plt.scatter(dimenstion_data[:,0],dimenstion_data[:,1],s=30,color='blue')\r\n",
        "\r\n"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNFfjv-E8v1k"
      },
      "source": [
        "# 이미지 데이터 그리는 함수\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "image_data : 이미지 데이터\r\n",
        "title : 제목\r\n",
        "\r\n",
        "n_images : 그릴 이미지 수\r\n",
        "IMG_SIZE : reshape할 이미지 사이즈(image_data의 크기와 반드시 같아야함)\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def draw_image_data(image_data ,title ,n_images=5, IMG_SIZE=64) :\r\n",
        "\r\n",
        "  plt.figure(figsize=(100, 10))\r\n",
        "  \r\n",
        "  for i in range(n_images):\r\n",
        "    ## display original\r\n",
        "    ax = plt.subplot(1, n_images, i + 1)\r\n",
        "    ax.set_title(\"Original Image\")\r\n",
        "    plt.imshow(image_data[i].reshape(IMG_SIZE, IMG_SIZE))\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUE5rbH3QP3Z"
      },
      "source": [
        "# ① 데이터 전처리\r\n",
        "\r\n",
        "csv로 부터 데이터 받아오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh_dTcTf0J5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a902073b-37cb-4667-cb83-e1b992365af8"
      },
      "source": [
        "path = input(\"PATH : \")\r\n",
        "col = input(\"COLUMN : \")\r\n",
        "\r\n",
        "dataset = align_timeseries_dataset(path,col)\r\n",
        "embedding_data = None\r\n",
        "predict = None\r\n"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PATH : ./Dataset1.csv\n",
            "COLUMN : Value\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9-anaKYROmS"
      },
      "source": [
        "데이터 cutting\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBT6Gqy0yT7R",
        "outputId": "1b1b8547-e4fc-4a7a-ba2e-a110abef6ca2"
      },
      "source": [
        "preprocessing_flag = 0\r\n",
        "\r\n",
        "preprocessing_flag = int(input(\"Data preprocessing( 1 : sliding window / 2 : trunction / 3 : padding) : \"))\r\n",
        "\r\n",
        "# 1 : sliding window / 2 : trunction / 3 : padding\r\n",
        "# 지금은 일단 1로만 가능\r\n",
        "\r\n",
        "if preprocessing_flag == 1:\r\n",
        "  shift_size = int(input('Shift length : '))\r\n",
        "  window_size = int(input('Window size : '))\r\n",
        "\r\n",
        "  dataset = sliding_window(dataset,window_size,shift_size)\r\n",
        "\r\n",
        "else :\r\n",
        "  pass"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data preprocessing( 1 : sliding window / 2 : trunction / 3 : padding) : 1\n",
            "Shift length : 172\n",
            "Window size : 172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-jX1KYtJflP"
      },
      "source": [
        "#② 잠재 벡터 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "0hzOag7ByNF1",
        "outputId": "32e79411-8b03-4d49-cb8b-1a226d440146"
      },
      "source": [
        "embedding_flag = 0\r\n",
        "\r\n",
        "embedding_flag = int(input(\"Embedding (1 : Auto Encoder / 2 : PCA / 3 : UMAP) : \"))\r\n",
        "\r\n",
        "# 1 : Auto Encoder / 2 : PCA / 3 : UMAP\r\n",
        "\r\n",
        "if embedding_flag == 1:\r\n",
        "\r\n",
        "  LEARNING_LATE = float(input('LEARNING_LATE : '))\r\n",
        "  BATCH_SIZE = int(input('BATCH_SIZE : '))\r\n",
        "  EPOCHS = int(input('EPOCHS : '))\r\n",
        "\r\n",
        "  embedding_data = embedding_AE(dataset,LEARNING_LATE,BATCH_SIZE,EPOCHS)\r\n",
        "\r\n",
        "elif embedding_flag == 2:\r\n",
        "  embedding_data = embedding_PCA(dataset)\r\n",
        "\r\n",
        "elif embedding_flag == 3:\r\n",
        "  embedding_data = embedding_UMAP(dataset)\r\n",
        "\r\n",
        "else :\r\n",
        "  pass\r\n",
        "\r\n",
        "draw_vector_data(embedding_data)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding (1 : Auto Encoder / 2 : PCA / 3 : UMAP) : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2kAAANOCAYAAACLIUQoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf4xd53kf+OcdzlgWRZqWK1qG4wkkx7UkogztYDBjbyEbbeJFFRcboz8M16ATqV2bKezZ7qbAoN1A6B/6bzbYH2D8g4q7dixSDQK7qzRR1dTBblUVtYccRaSFiFKSOrFvkhaiFImmTEua4Zz949XB3Llz7p0f9/Led2Y+H4C4vPeee86hMBDud57nfd5UVVUAAABQhrFR3wAAAACrhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUZHwUF73llluq2267bRSXBgAAGLknn3zyhaqqDje9N5KQdtttt8Xi4uIoLg0AADByKaXvdXtPuyMAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIasCe0WhGzsxHT0/mx1Rr1HQEANBsf9Q0AXG8LCxEf/nDEa6/l5089FXHmTMSFCxGTk6O9NwCATippwK7Waq0NaBERy8sRV65EzM+P7r4AALoR0oBdbX5+bUCrLS9HnD07/PsBANiIkAYUqXMN2cLC9taULSx0f296ejD3CgAwSKmqqqFfdGpqqlpcXBz6dYGdodWKOHYs4pVXIpaWIsbHI65di9i3L1fAJiYiDhzY3Jqy2dmIL30pf67dDTdE/NEfWZMGAIxGSunJqqqmmt5TSQOKMz+/GtAicsCqqtWgtbQU8dJLEe99b8Stt0bce2/3ytrcXMTBgzno1W64IeLxxwU0AKBMQhpQnIWF1YDWy6uvRjz/fMSv/3rE0aPNQW1yMlfcfvEXc3vj5z6XK2gzM73PbWQ/ADAqRvADfWu1cvVrYSGHn7m5/qpUR45EnDu3tc9cuRJx//25atZ5H5OTESdPbv5cne2W588b2Q8ADI+QBvSllECzshJx+nTE2Fj/99HZbrm0lJ/Pz28t7AEAbId2R6AvvQLNdj3zTPPrN97Y+3MrK4O5j6Z2y6UlI/sBgOEQ0oC+XI9AMzOTJzi2m5jIrYzd7NuXh4sM4j5mZtYOGqmvb2Q/ADAMQhrQl26BaruBptXK68tWVnLrYn2+AwciPvSh5s/8xE9EHD8+uPs4fjyP/G+3vJxfBwC43oQ0oC9zczlA1QGpDlRzc1s/V72+7eGHc0iqqlwh++Qn89qym25q/tzLL+fH/fsHcx+nT+frttu3L78OAHC9CWlAX+oR9ydO5KrViRPbHxrSub6tqnI17eDBfL5ua9VefDEHu4gc6Pq9j4WF9ZtfLy9bkwYADIfpjkDftjrivpuN1rfNzOSpjU17qC0tRVy9ujqCvx9N17EmDQAYFpU0YOTqjaO/972IlNa+1x6OPvKR9WvF2g1qAuMgWzgBALZKJQ0Yqc591tq1h6OFhYiPfWz9BMfO4wdR7apbOOfnc+ibnu5/g24AgM0S0oCR6lyHFpHXod1yS8THP54nKs7PR3z5yxsHtF7VrlYrn2dhIbczbhS6BtXCCQCwVUIaMFJN69BWViJuuy0HqW5Vttr4eMRP/VTvaldnte6ppyJ+7dci7rgjj/VXJQMASiKkASPVa0hHU5Wt0113bTwopPM8y8v5z3e+E3HxYsSZM9ufBAkAMGgGhwAj1WtIR1OVrV1KuSLWrh5CMj2dH1ut3udZWsqbZ8/PD+bfAwDQLyENGKle+6zNzKyGt3bj4xFHj0Z861sR73xnDmPve1/EnXfmNsnPfz7i3LmIU6dym+ORI83nqS0vRzzxxHX7JwIAbIl2R2Dkug3pmJvLrYh1q2JdZatDXL3W7MqV9ZtPR+TPvPJK/vuBA71bJ1dWBvfvAQDoh0oaUKxeVbaI1bVmTQGttrSU153V57nxxubjxvzfEAAohEoaULReo/A3WrMWsTqEpP08X/rS2mA3MRFx992DuV8AgH753TGwI7VaEa++uvFxy8t5r7Xa3FzEwYPNg0oAAEogpAHFaprUWL9+7FhuY9zIvn0Rp0+vPt+ohRIAYNS0OwIj0WrlNWULC3mKY+eG0gsLER/+cMRrr+XnTz21up/Z/fdHvPxyRFVtfJ3l5YizZ9e+1quFEgBg1AYS0lJK/0tE/I8RUUXE0xFxX1VVm2hEAvaiuhJWT1s8f37thtKt1tqAFpHD1pUrOaA99NDmAlrE6po0AICdou92x5TSj0XE/xQRU1VV/bWI2BcRn+j3vMDu0NSyWE9lrId+1KPy778/HzM1tTag1ZaXIx57bPPj8q03AwB2okG1O45HxI0ppaWI2B8RfzGg8wI7WLeK2eTk+qmMS0t57djY2MYTGzfjppsi7rtvfRslAEDp+q6kVVX15xHxKxHx/Yj4rxFxuaqqf9/veYGdr1vFrKpWpyvWUsqv9wpoN9wQcc89+dhexsZySNtIt8EkAACjNIh2x5sj4uci4vaIeGdE3JRSOt5w3GdSSosppcVLly71e1lgB2jax2xpKYeo/ftXN5AeG8vBq1cb4w03RDz+eMQDD6wPeJ1WViKefz7i85+PuP32iHvvXR/A6irfqVMR587lx2PH8j0LbgDAKA2i3fFnIuJPqqq6FBGRUvrXEfHfRcTp9oOqqnowIh6MiJiamtrkkn9gJ5uZyS2O7UFtYiLife+L+NM/XR3+UVW9B4HUAe2d78zVuX37mo8bH4+4dm3tea9dy4NGHnkk4mMfi3jmmXxfV66sr/JduZIHlqysNA80AQAYhkGEtO9HxAdSSvsj4kcR8dMRsTiA8wI73NxcDjl1GKoHeUREXL26Nkz1srIS8Su/EvHbv908UCQin/vmm3MFrenzly9HfO1r+Vrnz+fXrl1be9zycv5Tq9sz5+eN7AcAhmcQa9IWIuLrEfH7kcfvj8UbFTNgb+u2cfQzz2xtOMjSUsTXv947oB04kNerjff41VMdBpeW8t83WttWH9u5zxoAwPU0kOmOVVX9i4j4F4M4F7C7NG0c3dQGuV3tUxz/4i9ytWwzVlZy22Q9TXJsrHlN3NiYfdYAgOHqu5IGsFVzc7nyVQ8AGR/PVa3NVLY63XdfDoGTk3mEf7f1ap3GxiLe+taIO+/MA0NuuaX5uJTsswYADJeQBgxdZxvkL/5ixLe+FXH48NbOc8MNawPUwsLaNWW9rKxEvPhixLPPRnz/+7lVsmlbgOPHDQ0BAIZrUJtZA2xJZxtkqxVx663Ngz+a1BMf2wPUdtoo6+EgEbm61znk5IEHNn8uAIBBUEkDRq7es+zixd7HjY3l4z73uYg/+qMcytrPceVKrpCNbfH/bEtL+dpNQ05U0QCAYVNJA0Zufj5XsDZqVfzP/3ltMIvI4ez++/N6tKrKIS2lvDbtPe+J+C//ZePzjo/nYNY05AQAYNiENGCoWq0cyhYWcuCam8t/36hF8Rd+oTmgHTsW8fLLa/daq6pcTfvAB3L7ZOf7nfbtMxwEACiHkAYMTR2q6nVf589HPPRQxDve0f0zvdaGzc/nFsemANbewviRj0Q891z3a9x5p7ZGAKAcQhowNHVbY101W1qKuHw54gc/WHvcvn25BfHOOyPuvjtXueoQ1V6J++53u7cyjo/nc09NRfzlX3a/p4mJiPe9L2J2dm11T2gDAEYlVb16gK6TqampanFxcejXBUZrejri3LmNjzt6NOLRR9cHpc5KXL9SyiHt2rXV9Wzj4zkk3nFHxIc+JLABANdHSunJqqqmmt4z3REYmpmZ9XuRNbnxxuZg1FmJ6+aGGzbeGHtsLAey11/PIW1lJb++vBzx2msR3/lOxKlTORS2WhvfMwDAoAhpwNDMzeX1ZXVQaxqVPzGRK25NNjNgJCKHrI2aBG6/feNz1Xuozc9vfE0AgEER0oChmZxcuxfZpz4VcejQamirh4R0m7R45MjGFbLN+t73Nnfc0lLE2bODuSYAwGYYHAIMVedeZPUgkLNnc3Drtgas1Yp45JH1FbKUNq6adapbHTfaPy2id2UPAOB6ENKAkdrsBtLz8xFXr65//dChzW2E3e7gwTyW/+tfX//e2Fj+s7y8cWUPAOB6ENKAkWra3Lpp3P73vte8huzll3M1ramiNjER8clP5r8/9lh+vOee1T3XvvnNPP6/qvLn3/KWiN/93YjTpzeu7AEAXC9G8AMj0zlSP6VcxTp+POIf/+McqOr3xsZWJzB2Gh+P+ImfiPjjP86TGiPy8QcPRjz9dPeQtdlWSwCAQes1gl8lDRiZzpH6VZVD1kMPRfzGb+S/122M3QJaRD7mhRci9u/P56uqza1Ta2+17FXRAwAYJiENGJluI/VXVvIY/SY33hjxox+tf/3FF9c+r6q8hm1+fuM1b50VvfPnI86cyZMoBTUAYNiM4AeGqtWKmJ3N7YWvvppbFTdrYiLib/yNzR+/2fH5nRU9+6MBAKOkkgYMTWfFanw8tzQ2Df0YH4/Yty9X1ZaWckDbvz/i935va9f80Y/ydXtVxJoqevZHAwBGRSUNGJrOitXycg5i731vfhx74/9IExN56Mfjj69ufH3iRB6b//rrva/Rudn1xYs5GC4srFbwZmdzcKvNzKxuqF2zPxoAMCqmOwJDMz0dce7c+tePHYv47d/uPWmx1Yq4/fbV6Y2d6hH673hHxHPPrX2vqSp34MDqmrPOCl/n+wAAg9ZruqNKGjA0MzPNa9CefTY/njyZK14nT64PR/PzvSc8vve9edz+W96y/r3l5TyIpNuas8nJHMjaq3YCGgAwKkIaMDRzc7mi1enatY2HdCws9B6rf+hQDlVNrYtNOtec1eP4u4VEAIBhEdKAoZmcjLjjjvWvLy9vPKSjV/hqXz82N5dbFetjJyYibrhhfQXPmjMAoFRCGjBUH/rQ9oZ01OGrKWwdOJDfj2huXXz88TyIpD24tX8GAKAkBocAQ9XPkI5WK7dFPvFEXp82NhZx993rh4w0WViI+PSnI7773Yh3vzvi134tV+cAAEah1+AQIQ0YujpsdZvkOKjzLyzkIHb8eMQ995jeCACUQ0gDitcZrLYb3JoqdWNjeTjJ8vLqcRMTuRXy5MnB/RsAADarV0hrGIYNMFydwer8+YgzZ7ZX6ercMLt+7NQ53REAoBQGhwAj1xSs2vcx24qFhe7BrJ3pjgBAqYQ0YOSagtXSUsRXvhIxO5srbZvVNKp/fDyP4TfdEQDYCYQ0YOS67YH2wx9GnDqVWyE3G9Sa9kk7eDCP4W8fy7/doSGtVg6O09NbD5AAAJthcAgwcp1r0pocPRrx6KObC1abnR651WEl/WwfAADQznRHoHh1YPrKV3IFrcmhQxEf+1jEM8/0NwGyvt5WA9fsbK7stQdJUyIBgO3oFdK0OwIj0946OD+fQ9d99zW3PkZEXL4c8bWvRZw7t/U2yE7bGVbSbe2cKZEAwCAJacBI1JWsU6fWhq7jx3NFq5u6+N/PBMiI7QWuprVzpkQCAIMmpAEj0a2Sdfp0bjk8enTjc/RTxdpO4GoaSmJKJAAwaEIaMBK9KlmTk3lIyM03rwaisYb/W/VTxdpO4JqczAFyEFMiAQC6GR/1DQB708xMxPnz64dw1KGrDkT1lMa77op45JGIq1fXDvrYbhWr8/y9pkB2fs6QEADgejLdERiJ7UxX3OxofQCA0vWa7qiSBozEdipZqlgAwF4gpAEjI3QBAKxncAgAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFCQgYS0lNJbU0pfTyk9m1K6mFL64CDOCwAAsNeMD+g8/1dE/Luqqv5eSulNEbF/QOcFAADYU/oOaSmlQxHxoYi4NyKiqqrXI+L1fs8LAACwFw2i3fH2iLgUEV9JKT2VUvpySummzoNSSp9JKS2mlBYvXbo0gMsCAADsPoMIaeMR8VMR8cWqqt4fET+MiH/WeVBVVQ9WVTVVVdXU4cOHB3BZAACA3WcQIe3PIuLPqqpaeOP51yOHNgAAALao75BWVdV/i4hWSumON1766Yh4pt/zAgAA7EWDmu44GxFn3pjs+N2IuG9A5wUAANhTBhLSqqo6HxFTgzgXAADAXjaQzawBAAAYDCENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgAwtpKaV9KaWnUkq/M6hzAgAA7DWDrKT9k4i4OMDzAQAA7DkDCWkppXdFxEcj4suDOB8AAMBeNahK2v8ZEXMRsdLtgJTSZ1JKiymlxUuXLg3osgAAALtL3yEtpfS3I+L5qqqe7HVcVVUPVlU1VVXV1OHDh/u9LAAAwK40iEraX4+I/yGl9KcR8RsR8TdTSqcHcF4AAIA9p++QVlXVP6+q6l1VVd0WEZ+IiP+3qqrjfd8ZAADAHmSfNAAAgIKMD/JkVVX9h4j4D4M8JwAAwF6ikgYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCB9h7SU0mRK6f9LKT2TUvqDlNI/GcSNAQAA7EXjAzjHckT806qqfj+ldDAinkwpfbOqqmcGcG4AAIA9pe9KWlVV/7Wqqt9/4+9XIuJiRPxYv+cFAADYiwa6Ji2ldFtEvD8iFhre+0xKaTGltHjp0qVBXhYAAGDXGFhISykdiIhvRMT/XFXVDzrfr6rqwaqqpqqqmjp8+PCgLgsAALCrDCSkpZQmIge0M1VV/etBnBMAAGAvGsR0xxQR/zIiLlZV9b/3f0sAAAB71yAqaX89Ij4VEX8zpXT+jT8/O4DzAgAA7Dl9j+Cvquo/RUQawL0AAADseQOd7ggAAEB/hDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQDY9VqtiNnZiOnp/NhqjfqOALobH/UNAABcT61WxLFjEa+8ErG0FHH+fMSZMxEXLkRMTo767gDWU0kDAHa1+fnVgBaRH195Jb8OUCIhDQDY1RYWVgNabWkp4uzZ0dwPwEaENABgV5uZiZiYWPvaxERenwZQIiENANjV5uYiDhxYDWoTE/n53Nxo7wugGyENANjVJifzkJATJ3L17MQJQ0OAspnuCADsepOTESdPjvouADZHJQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAIDitVoRs7MR09P5sdUq41wA10OqqmroF52amqoWFxeHfl0AYOdptSKOHYt45ZWIpaWIiYmIAwciLlyImJzM78/PRywsRMzMRMzN5de3cy6AYUkpPVlV1VTTeyppAEDR5udXQ1VEfnzllfx6HbpOnYo4dy4/HjvWvTrW61wApRDSAICiLSyshqra0lLE2bNbD129zgVQCiENACjazExuS2w3MZHXlG01dPU6F0AphDQAoGhzc3ndWB2u6nVkc3NbD129zgVQCiENACja5GQe7HHiRA5fJ06sDvrYaujqdS6AUpjuCAAUZ6sTG+fnc4vj9HTvYwFK0Wu6o5AGABTFmHxgLzCCHwDYMTY7sdGm1MBuNT7qGwAAaLeZiY2d1bbz5yPOnFFtA3YHlTQAoCibmdjY76bUqnBAyVTSAICizM1FPPRQxA9+EFFVESlF7N+/dmJjP5tSq8IBpVNJAwCKlNLax3ZHjjR/5q67Nj5vv1U4gOtNSAMAijI/H3H1asTKSn6+spKfDypE9VOFAxgGIQ0AKEq3EPWVr6yuH3vmmebPXry48fk3s+YNYJSENACgKE0hKiLihz+MOHUqryc7cmRrQavVirj33ohbb434V/8qt1COj69+7sCBtWveAEZJSAMAijI3l0NTU1BbWoq4ciX/vf2YXkGr1Yo4ejTi13894vnnI158MeL11yPGxnLgO3HC0BCgLEIaAFCUyckcmk6ciLjxxvXvLy/niYz1MceORdx5Z8SP/3het9Y+Tr/VivjoRyMuX15/nqWliLvvjjh5sjmgGdMPjEqqqmroF52amqoWFxeHfl0AYLharRycFhZyG+Pc3NYqVnfeGfHcc+tfv+OOiGefXT9Ov66oXbiQjzt2LOKll7qff3o631vTfXc7r4obMAgppSerqppqes8+aQDAdTGI/cheeKH59RdfzI8bjdN/5ZXu506p+xq2Xuc9eXJz9w6wXdodAYDrYhD7ke3b1/z62BvfYHqN0296r91b3tJ9WIgx/cAoCWkAwHUxiKBzzz29X+81Tr/blMg3vzniF34h4umnu1f0jOkHRklIAwCui0EEnQceiDh0KLcmRuTHQ4fy6xHrJ0G2T3lseu/mmyP+8A8jvvrV3i2Xvc4LcL0JaQDAdTGIoDM5mSten/1sDnef/ezaClj7JMjp6bXj9Hu9t5nrbvezAP0y3REAuG7q6Y5nz+aws9XpjtdTv5MnAfrRa7qjkAYAFOd6Bygj9oFR6xXStDsCAEWpA9SpUxHnzuXHY8cGu5n0ICZPAlwvQhoAUJTNBqhWK2J2NrdRzs5uLcQZsQ+UzGbWAMBIdbY2PvHExgGq342yZ2byZ9qvY8Q+UIqBVNJSSn8rpfRcSumPU0r/bBDnBAB2v6bWxmefjRjv+DVyZ4Bqqra99FLERz+6tqLWrdpmxD5Qsr4raSmlfRHx+Yj4SET8WUScSyn9m6qqnun33ADA7tYUtsbHI5aX1x63vBxx/Pjq86Z2xYg8nv/YsVxRi+hdbbtwodzJk8DeNoh2x+mI+OOqqr4bEZFS+o2I+LmIENIAgJ6awlZnQIuIqKqIL34xtylGNLcr1trXr3UGwJdfjrj//tXNrE+eHNg/BWBgBtHu+GMR0b5U98/eeG2NlNJnUkqLKaXFS5cuDeCyAMBONzOz2nK4kYceitHkLi8AACAASURBVLj33lz1unIlYv/+5uPq9WtNAbCqIk6fHuykSIBBG9p0x6qqHqyqaqqqqqnDhw8P67IAQMGa1obdcEPzsSsrOaidOxfx8MP5tTvuWH9cvX5tZiYipfXvV5VR+0DZBhHS/jwi2ju43/XGawAAPdVrw06cyMHqxImIxx+P2Lev+fiVlfy4tBRx9WrEBz4QcfPNzQNA2tewdZ7DqH2gZINYk3YuIv5qSun2yOHsExHxyQGcFwDYAzrXhrVaEe95T8Rzz/X+3NJSxMWLzQNAIiLuuaf5c0btA6XrO6RVVbWcUvpcRPxuROyLiP+7qqo/6PvOAIA9px7Jf+XK2tdTym2K7eqw1TQAZHY2Dw3p/MzYmFH7QPkGspl1VVX/NiL+7SDOBQDsXfVI/s4Jj296Uw5cKyv5vY32Nes2ov+WWyIWF43aB8o2tMEhAAAb6RauXnstB7R9+3Kl7cSJ1b3QmjarbpoaOTER8fGPC2hA+YQ0AKAYvUbyLy/noHb33avtjUePRnzhC3ni4xe+kJ+3Ws1TI7U5AjvFQNodAQAGYW4u4syZtZtQt6v3QIuI+KVfirh8efW9lZX8/Jd+KeId74j48R/Pr42N5WA3N6eKBuwMQhoAUIx6JP/8fMRv/mbEpUtrh3/Uw0JarYhvfKP5HN/4RsT4eA507RU0AQ3YKbQ7AgBFqac1Li5GvPWtzS2L8/PrJzfWqmq1Cre0lKty3TavbrWa17QBjJJKGgBQpPaqWuceaL/5m5s/T3uLZLt63H/dWnn+fG61vHBB1Q0YLZU0AKBYdVVtYSEHtPvvj7jttojnn9/8ObptXl2P+99s1Q1gWFTSAIDi1VWvl1/u3ubYTbepjk3j/rtV3QCGSSUNACheXfXaakB729tyNW5+fv16s5mZPGCk3fh4c9UNYJiENACgeN02ue6UUn6cmMh//8EPIr7znYhTp3Ilrj2oHT8ece3a2s9fu5ZfBxglIQ0AKF6vTa4jciA7dCji538+V8LuvDNi3768AXZE83qz06fzMe3Gx/PrAKMkpAEAxZuby2vLOtsTI3LQ+vmfj3j66YivfjVX3d785tWAVltaylMh62rawkLzMdakAaNmcAgAULz2cfxPPBGxshIxNhZx993NG1XPzOSR+p0tki+8kNseL1xoPqbbJEiAYRLSAIAdoR7Hv5FWK+LKlRzkOq2srLY9zs3lfdHqMfztm2UDjJKQBgDsGu0bVHcOBanVLY3dNsu2kTUwakIaALBrdG5Q3aS9pXGz1TmAYTI4BADYNTYa1a+lEdgJhDQAYNdoGtU/Ph5x9Giunp04kVsctTQCJdPuCADsGt2GgTz6qGAG7BwqaQDArlEPAzlxQuUM2LlU0gCAvrRaeWDHwkJuNxz1hETDQICdTkgDALatfeT90lLeHPrMGdUrgH5odwQAtq1z5P3S0upm0QBsj5AGAGxb08j7erPorWq1ImZn81qy2dn8HGAv0u4IAGzbzExucWwPau2bRW+WtkmAVSppAMC2zc3lEff13mTb3Sxa2yTAKiENANi2QY28H2TbJMBOp90RAOjLIEbeb6dtsrTR/wCDkqqqGvpFp6amqsXFxaFfFwAoU+eatLptsltVbqvHA5QmpfRkVVVTTe9pdwQARm6rbZPWsAG7mXZHAKAIW2mbtIYN2M1U0gCAHWdmZnWiZG07o/8BSiSkAQA7zqBG/wOUSEgDAHacQY3+34pWK2J2Nl9vdjY/B7geTHcEANiAaZLAoJnuCADQB9MkgWES0gAANmCaJDBMQhoAwAZMkwSGSUgDANiAaZLAMAlpAMCucb0mMI5imiSwd5nuCADsCiYwAjuJ6Y4AwK5nAiOwWwhpAMCuYAIjsFsIaQDArmACI7BbCGkAwK5gAiOwWwhpAMCuYAIjsFuMj/oGAAAGZXIy4uTJUd8FQH9U0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKEhfIS2l9L+llJ5NKX0npfT/pJTeOqgbAwAA2Iv6raR9MyL+WlVVPxkRfxgR/7z/WwIAANi7+gppVVX9+6qqlt94+u2IeFf/twQAALB3DXJN2j+MiMe6vZlS+kxKaTGltHjp0qUBXhYAAGD3GN/ogJTS70XEOxre+uWqqn7rjWN+OSKWI+JMt/NUVfVgRDwYETE1NVVt624BAAB2uQ1DWlVVP9Pr/ZTSvRHxtyPip6uqEr4AAAD6sGFI6yWl9LciYi4iPlxV1dXB3BIAAMDe1e+atF+NiIMR8c2U0vmU0pcGcE8AAAB7Vl+VtKqq3jOoGwEAAGCw0x0BAADok5AGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFAQIQ0AAKAgQhoAAEBBhDQAAICCCGkAAAAFEdIAAAAKIqQBAAAUREgDAAAoiJAGAABQECENAACgIEIaAABAQYQ0AACAgghpAAAABRHSAAAACiKkAQAAFERIAwAAKIiQBgAAUBAhDQAAoCBCGgAAQEGENAAAgIIIaQAAAAUR0gAAAAoipAEAABRESAMAACiIkAYAAFCQgYS0lNI/TSlVKaVbBnE+AACAvarvkJZSmoyI/z4ivt//7QAAAOxtg6ik/R8RMRcR1QDOBQAAsKf1FdJSSj8XEX9eVdWFTRz7mZTSYkpp8dKlS/1cFgAAYNca3+iAlNLvRcQ7Gt765Yj4XyO3Om6oqqoHI+LBiIipqSlVNwAAgAYbhrSqqn6m6fWU0tGIuD0iLqSUIiLeFRG/n1Karqrqvw30LgEAAPaIDUNaN1VVPR0Rb6+fp5T+NCKmqqp6YQD3BQAAsCfZJw0AAKAg266kdaqq6rZBnQsAAGCvUkkDAAAoiJAGAABQECENAAAYqVYrYnY2Yno6P7Zao76j0RrYmjQAAICtarUijh2LeOWViKWliPPnI86cibhwIWJyctR3NxpCGgAAMDStVsT8fMTCQsTMTMSVK6sBLSI/vvJKPubkydHe66gIaQAAwFA0Vc1WViKuXVt73NJSxNmzzZ9vD3hzc7uz2iakAQAAQzE/v75qNjYWkVJEVa0eNzGR16e120ttkQaHAAAAQ7GwsBrQaisrOahNTOTnExMR+/fnNsj2QSJNAa9ui9xtVNIAAIChmJnJFbD2oDYxEfHJT0YcPJhbHO+6K+KRRyIefnhtxezWW9cHvG5tkTudkAYAAFwXnWvIjh/PgauuiE1MRBw4EPHAA6sti7OzEVevrq+YXb68/vwp5VC32whpAADAwHVbQ/bYYxGnT+cK2PT0+uEfTS2Rnc9rVZWrbq3W7lqXJqQBAAAD17SG7OWXI774xYivfrX755paInu5enX3jes3OAQAABi4popYVeUqWqvV/XNzc7kFcnyT5aTduC5NSAMAAAZuZiavGetUVbny1Wrl9WftExwjctvihQubX2vWNK5/p0tV+4YEQzI1NVUtLi4O/boAAMBwtFoRt9++fqPqiLxW7fvfXz9ApH3Ps+npiHPnms9d76vW9LmdIqX0ZFVVU03vqaQBAAADNzmZpzmOdSSOiYm8N1qvPc9arYhXX+1+7je9KQe9Eyd2ZkDbiJAGAABcFw88kPc/q9seU8obVafUfc+zeirkxYvdz7uyEnH33XlYyG4LaBFCGgAAcJ21h7SIiPe/P1fU2tVry+qpkMvL3c+3G4eFtBPSAACA62J+Po/IX1nJz1dW8qbU3/52rqi1T3AcG8vtkU1TITuNje3OTaxrQhoAANCo2wTGzeoWuJ57Lge29vVq165F3HNPxJEj66tsnVZWVjex3o2ENAAAYJ16bdipU3nK4qlT+flWgtGRI+sHh9R++MO1AW55Obc5RuSJjXVQm5jIg0I61ZtY97r/fgLmKAlpAADAOvXasG4TGDfSauVqV93q2GllJY/Rb7e0lAeGXLiQJzdOT+fHO+9c//le69IGETBHSUgDAADWaWpV3MrAjno9Wjcprd/sunNj6jrE9Ro00u3a/QTMURvf+BAAAGCvmZmJOH9+bVDrFYw6bTQApKryeP5XX127ofXx47nqVYes8+fzkJH9+3Poaz92bm7z195JEyFV0gAAgHXm5tavDesVjDrNzPQeADI+HvF3/s7atsYLFyJOn15fBbt6NeJjH1t/bLc90pquvZWAOWqp6mwEHYKpqalqcXFx6NcFAAA2r9XKLYJnz+aAMze3+c2j63Vh7YGr0/R0rnp1vnbuXPdj63taWMhhrOmeOq9dB8xewW7YUkpPVlU11fSeSloPO3kiDAAA9GtyMuLkyRyITp7cWsCZnFwdAPL2t2+8/qzWqwrWNBDk6NGIv//3I269Nf+59978mc7hIyUFtI2opHVRQvrezG8JAACgdBt9t27/3nvkSJ4K2bn+7MKFfMypUxtvdn3oUMTTT5f93blXJU1I62J2dv0PwMRETuEnT17/65cQEgEAYFC6tU42fe/dvz+vQbt4MeKuu/Lnn3km4nvfi3j++Y2vlVLEZz87nO/t29UrpJnu2MUwJsL0qpT1Ghta8g8bAAA0qVsnOzV97716NU9+/PrX1wa4zpbJbqpq50xybCKkddHvyNGNdP7G4Pz5iDNnVitlO31sKAAAbEav772dAa5uAhwby5th14+dUto5kxybGBzSRb8jRzey0QZ7O31sKAAA1HoN5Gv63ptSbnPsttdaSnnt2qc+lStuTe9fubJzB/9Zk9ZDPyNHN7KZ0aLWpAEAsNMtLER8+MMRr72Wn4+P52DVPjTk6NGIy5fXfu7Qobwu7eGHuwe1b30r4p3vjLj//ohHH4144YX8elWV//3ZCP5t6mfk6EY2qpS1jyzdiWNDAQDYfbayRVWrlcfhf/CDqwEtImJ5OeKllyKmpvI5InIYG+tIJlev5scDB5rPX1URn/50/n781a9GfOIT+ft0XYPq7FTbSVTSRkSlDACAnWQr31/rYy9fbl4zVqsnOY6PR7z44vr3p6fz8JB3vzuHu0433ZTvpz62V6daaVTSRqTXbxpUygAA2Ek2mqnQdGyvgFaf4/Ll5oBWd5lNTq6O4e/07nev/n03zXRQSRugzW7CJ4gBALDTbKVS1e3YzUop4q1vXTv5/IMfXG1lrI/51rdyOIvYeZ1qKmlDUP9QnDqVfyAfeij/VmAzv2kAAIDSbaVSNTOTWxi36/DhteFqZiYHsqNHc4vj0aNrA1rE7upUE9IGpLP821Tatc8ZAAA71Va2qDp+POLatfWv/+zP5qmNvUxMRHz84+vD1cxMnuB4330Rb35zxOnT6weXXM/Bf8MkpA3AwkLEl7/cPBq03U7tiQUAgK1Uqk6fjti3b+1r4+N5DdnTT0e87W3dr9Mt+HV2rp06lZ/v1L3QeumjCElEc39sN/v3D24zbAAAGLa6UrWRhYX10xiXl3NX2eRkxNvfHvGXf7n+c3/lr0Q89VRz8Os1uGQz97STqKRtQdO0xk9/enMBLaW8/8NOLbkCAEA3nd+Tjxzpvn6t1Yr4kz9Zf459+yL+wT/o/n15YWF959puXU6kkhZrpzLOzORqV7e9Hur0fv58xJkzEa++urlrVFXEY4/l8whqAADsFk3fk/fvz386J53PzeXv3U3r1cbHe3edzczkc7cHtd26nGjPh7Ru4auzv7ZbefXgwYgf/Whz13rhhXytnTplBgAAOjV9T756NeKTn8zflc+ezUGqLoQ0tUJGRNx5Z+/vyHNz+Xt654j93bicaM+3O252U75u5dVbb82tjJ0OHlz/+sqKMfwAAOwu3b4nX7zYPGnxyJH135MnJiLuvrv3dXbTiP2N7PmQttne1qZ9IVLKu6P/3b8bcccdq3s2fPvbEX/wB3l/h05N525a6wYAADvBVvZPa7UiHnlk/UyHzQ7Y2y0j9jey50PaZn+oOveFiMg/XM8/H/Fbv5UfL16M+M538jknJ/P+Dhudey+NEgUAYPfZyv5p8/MRP/zh2tcM2Ftvz4e0zf5QtZdX3/72iLG2/3JLSxEvvRTx0Y+uDVebOfdm2y2bqMABADBqW2lDfOKJ9evRqirPhWBVqjYzP37ApqamqsXFxaFft5t6umPnosZupqdz1avJzTev/aHsPPfx43lzv3qS5H/8j7n61nSNhYX191h/7vjxiHvuWb9wcrf25QIAsPP95E/mzaw7HT3a/J14M1PYd6qU0pNVVU01viekbd3sbG5L7FzLFpHLtYcP51bHzh+iViv/AF65koeIjI3lUaMrK2t/ozAxkX8DUW/K1zmBcmIif/batd6fAwCAkhw71hzGbrwx4h/9o7Xfn5u+A++mokSvkLbn2x07baaFsG5jbFKvU2tfW1af8/3vj7h8OYeyiPz4+us5cG21JfK119aXinfrZn4AAOwOH/pQLlJ0+tGP1s9m6GdZ0E4npLXZ7BCPuu/26NHu56p/iO6/Px/3hS/kSZBN3vKW3j28TRMom+zWzfwAANgd5ubyVlWdw/Ui8vfdy5fz9+eIzU9h342EtDbd0vr996+vrk1ORjz6aF6D1vTbgPrzv/M7a6tnTcbGeo8S7TaB8oYbNjdFBwAAStA+ZOSmm9a/v7KS5ze0Wlsb7b/bCGltuqX106ebq2uTkxGPPRaxb1/z+SYm8m7rG7nnnt7vd5sS+fjje2MzPwAAyrfZyeP1Xmf33bd2YnptZSUXT7Yy2n+3MTikTdNAkJTyn/ZKWPtwkCtXIh5+eH24GxuLOHQoP3Zrc0wptzo+/fTG4WqrEygBAGBYtjPko9WKuP32PAyvUz3pfDd/BzY4ZJOa0vrY2PpWxXo4yK/+asTXvta8XuyWW3KV7ZZbmq81Nhbxtrfljfs2Y3Iy31/9Azs/b180AADKMD+fixfty4auXOk95GNyMm8rlf7/9u4vNtKrvAPw76ztAGGTiAChpJgKqhQSQEYotUFqEpCaAuUi/FEiCitxUcEGwd5VK6oqaqW9oVarXkRtRREoQaRFuaEsTYECrQIXkTeL5CUhIUpaKAa2hNCEZAlNnOzpxeeRx/bM2F47ns8zzyOt7PnG4zmJjkbfz+857ylrr3cvaexU3fptCxpVKmlZe/7CFVc01+6/v5kc/Splg5TSBLAzZza2yV9vcrLZPLnZUsVRb0EKAMD+1a+1/szM4IOqx/ked1AlrU/Li/GxfmIsLq6dGEtLyfHjaxuKbKbW/ksc13vmmeSxx5rmJLfc0v/nBrUgdS4aAADD1K/uM6h5XrLaSGRUlzSeq7Ff7rjZ+QvdHWguueS5GUOtq11s+hnnFqQAALRbrwYgg653G9cljYOMfUjbSvjpTJyTJ5u298+FWgev2R3nFqQAALTbVVdtPJZqaqq5zvaNfUgbFH7WtxFNmrb3W/mLwHpTU81etX7t+s+eHVwVG+cWpAAAtNv6Q6rdq+7M2Ie0fuHn0KFmr9r689EuvTR573u39rsnJ5vK28xMs1zyrruSj360d8fHzapi3csunYsGAECbuFfdXbo7pvf5C/PzG89Mm5pKPvCBprX+ww8P/p0TE03QO3Zs4+Ts1cXm/PObdvz33ddU9w4davapLSw0j22gBACA0TGou6OQ1sfsbFNBW6+U/t1runUC3QUXrA1aP/1p8uEPJw880HR2rLU59Hp5OXnqqbXt+icmmhb+49SKFAAAxoEW/Odgbq5px7++qchWM+3yclMJO3BgtbX/rbc2566t99hjvX9H5/T15eXk0UeTd70rueMOQQ0AAEbZ2O9J62f9XrXtNgsppWkGsv7U9Z24555mmeSgVv0AAMD+JqT1sX7zY69mH4PUuvWq23Z0n+EGAACMHiFtgO6D9W64YfuvP5dW/ZtxgDUAAIw2IW2LOmc/bFd3a/8XvnDn43CANQAAjDYhbRu2WxmbmEiuuy655JLkRS9KXvGK/odZD/odDgUEAIDxobvjFs3PJ08+ub3XPPNM8uUvrzYQ2exstV4OHWoqeN1nuOnuCAAAo0tI26KFhY3t+DdTa3P22bk677zeh2EDAACjy3LHLZqbW112uFcuv1xAAwCAcSOkbdH6c9O6TfapR/bbw3bxxc0etUGmppKrrhr8M0tLyZEjzTLII0ecnwYAwOgap3vfUp+Lw7w2ceWVV9aTJ0/u+fvu1NJSszftxImmypUk99/fTJRrr02uvz55+unmeinN117/e2dmktOn++9R6zQIOXWqfyVtaan5PWfONMswt/IaAADYj0bx3reU8p1a65W9nlNJ26JOQFtYaELZsWPJLbc0j2++Ofn619cGsn6HWU9ODq6QTU42B2hvNuFuuil57LHVfXLLyw66BgBgNM3Prwa0ZPTvfTUO2YJOcn/iiaZj4913J5/+dHLnnc1etWRwY5HJyeZ13S30n3giufXWjT/7wQ82oW+z8Xz+8xtDoIOuAQAYRb3utUf53lclbQvm51cDWsdTTyXXXLO6FnZurvcetFKapZGzs2srZMeOJRddtPqaAweax8eONY8Hrbmdn+9dpSvFQdcAAIyeXk38pqZG997XnrQtmJ1tqme9vPjFyaWXJr/+dfLQQ/1fv7Cw8Xr3HrfuM9A2W3PbbzwTE8kPfrB/1+UCAEAv9qSxQWdJYy+/+EVyzz39A9rUVFNJW18VW7/HrfuQ6k7lrt+a215/SThwoDn4er9OUgAA6Gd6uglkhw9vXKE2ilTStmBpKbnssu0fTF1KcuGFzfdPPrma+s8/f+O1gweTr3yl2Wv2mc80lbn1ZmaSxcXR/EsCAACME5W0HZqebpqEPO9523vd85+fvPvdya9+tbYq9vjjvStl11yTfOpTvQNakpw9uzqecfpLAgAAjBPdHbdobi558MFmyeHttyePPLIamvq54IKm8tXdcCTp3Z6/X2fIbt2NSaanN+8CCQAA7D8qadvQCUYnTzadGCc3ibjvfOfmQW6rNjtfDQAAGA1C2jnoLDe88cZmb9hrXtPsP+soZbWdfvf1bhMTq80/pqaapZT9Qt/UVFOVO3p0d/87AACA9hHSzlGnqra4mHz/+8lddzVhbXKy2Yt27bXNz1199cbwNTnZdGLs3lN2551NEOsEt4mJZnnjC16QvPa1TVMRe84AAGD06e64C5aWkje8IfnlL9dev+ii5HOfS264YbUz5ORkE8Z6NfrotOX/9reb4Pfss81+tu7ujclq6/65ubWt+wEAgP1hUHdHjUN2wfx807FxvccfT66/Pnn66dVrzz6bvOUtyfve1z9knT7dvKaTnzvdH2+6KTl+fLX1/uJictttOjsCAMAoUUnbBbOzyd13b/916ytk3Wef9XLJJcmjj659fmqqWS6p0yMAAOwfz2klrZRyJMnHkjyb5I5a69i1t5ibazo+bjfvdipk8/PN40EBrbNXbf3zy8vJiRPbe18AAKC9dtQ4pJTytiTXJZmptb4uyV/tyqj2maNHkwsvPLfXdkLWwsLggHbwYNPSvxPWup+bnT239wYAANpnp90dP5rkk7XWp5Kk1vrwzoe0PywtJUeONAFpfj752tea7o7b1QlZc3MbA9iBA80Sx8OHmyWRx441Ya27df/Bg1rzAwDAKNnRnrRSymKSLyV5R5L/S/IntdZNd2ft9z1pS0tr9491wtL0dPLd72799wzak9b9XHdTkE4HyBMnmnCnuyMAAOw/O9qTVkr5RpLf6PHUn628/uIkb07yu0luL6W8uvZIfqWUjyT5SJK88pWv3ProW2h+fu3+sc7eslqbcNVv2WLHeecll1+eXHXV2pB16tRqALv88uba+i6QnfPZAACA0bTTStpXk/xlrfU/Vh7/Z5I311p/Puh1+72S1q+b48xM8qMfrQa4ycnk7NnmX7fNOjL2q9RptQ8AAKNhUCVtp3vS/jnJ21be5HeSnJfkkR3+ztbrtX9saqqpjJ061QSw2dnkxhuT179+4+s368jYr1LX6QIJAACMrp2GtM8meXUp5d4kX0jyoV5LHUfN0aP9G3h0liMuLDRfr756+x0Ze3V61GofAADGw45CWq316VrroVrr62utb6q1/vtuDazNpqfXVsw63Rd7LUUcFOj66Vep02ofAABG3472pJ2r/b4nbbu225HRnjQAABhtO+ruyM5ttyNjp1Kn1T4AAIwfIa2ltNoHAIDxtNPGIQAAAOwiIQ0AAKBFhDQAAIAWEdIAAABaREgDAABoESENAACg/waUkgAABSlJREFURYQ0AACAFhHSAAAAWkRIAwAAaBEhDQAAoEWEtHWWlpIjR5LZ2ebr0tKwRwQAAIyTyWEPoE2WlpKZmeTMmWR5OVlcTG67LTl1KpmeHvboAACAcaCS1mV+fjWgJc3XM2ea6wAAAHtBSOuysLAa0DqWl5MTJ4YzHgAAYPwIaV3m5pKpqbXXpqaa/WkAAAB7QUjrcvRocvDgalCbmmoeHz063HEBAADjQ0jrMj3dNAk5fLipnh0+rGkIAACwt3R3XGd6Orn55mGPAgAAGFcqaQAAAC0ipAEAALSIkAYAANAiQhoAAECLCGkAAAAtIqQBAAC0iJAGAADQIkIaAABAiwhpAAAALSKkAQAAtIiQBgAA0CJCGgAAQIsIaQAAAC0ipAEAALSIkAYAANAiQhoAAECLCGkAAAAtIqQBAAC0iJAGAADQIkIaAABAiwhpAAAALSKkAQAAtIiQBgAA0CJCGgAAQIsIaQAAAC0ipAEAALSIkAYAANAiQhoAAECLCGkAAAAtIqQBAAC0iJAGAADQIkIaAABAi5Ra696/aSk/T/KrJI/s+ZtDfy+JOUm7mJO0kXlJ25iTtM1W5+Rv1Vpf2uuJoYS0JCmlnKy1XjmUN4cezEnaxpykjcxL2sacpG12Y05a7ggAANAiQhoAAECLDDOk/cMQ3xt6MSdpG3OSNjIvaRtzkrbZ8Zwc2p40AAAANrLcEQAAoEWENAAAgBbZ05BWSrm+lPK9UsrZUsqV657701LKQ6WUB0opb9/LcUFHKeUvSik/KaUsrvz7w2GPifFUSnnHyufhQ6WUTwx7PFBK+WEp5Z6Vz8aTwx4P46mU8tlSysOllHu7rl1cSvl6KeXBla8vGuYYGS995uSO7yf3upJ2b5L3JvlW98VSyhVJ3p/kdUnekeTvSikTezw26PibWusbV/7967AHw/hZ+fz72yTvTHJFkj9a+ZyEYXvbymejM6kYllvS3Ct2+0SSb9ZaL0vyzZXHsFduycY5mezwfnJPQ1qt9f5a6wM9nrouyRdqrU/VWn+Q5KEks3s5NoAWmU3yUK31v2qtTyf5QprPSYCxVmv9VpL/XXf5uiS3rnx/a5J37+mgGGt95uSOtWVP2m8mWep6/OOVazAMHy+lfHelfG3JBMPgM5E2qkn+rZTynVLKR4Y9GOjyslrr6ZXv/yfJy4Y5GFixo/vJXQ9ppZRvlFLu7fHPX4FphU3m6N8n+e0kb0xyOslfD3WwAO3xe7XWN6VZhvuxUsrVwx4QrFebs6WcL8Ww7fh+cnK3R1Rr/f1zeNlPkkx3PX7FyjXYdVudo6WUTyf5l+d4ONCLz0Rap9b6k5WvD5dSvphmWe63Br8K9sTPSikvr7WeLqW8PMnDwx4Q463W+rPO9+d6P9mW5Y7Hk7y/lPK8UsqrklyW5MSQx8QYWvlw73hPmmY3sNfuTnJZKeVVpZTz0jRWOj7kMTHGSikvLKVc0Pk+yR/E5yPtcTzJh1a+/1CSLw1xLLAr95O7XkkbpJTyniQ3J3lpkjtKKYu11rfXWr9XSrk9yX1JnknysVrrs3s5NlgxX0p5Y5qlEj9Mcni4w2Ec1VqfKaV8PMnXkkwk+Wyt9XtDHhbj7WVJvlhKSZp7h3+stX51uENiHJVS/inJW5O8pJTy4yR/nuSTSW4vpfxxkv9OcsPwRsi46TMn37rT+8nSLN0FAACgDdqy3BEAAIAIaQAAAK0ipAEAALSIkAYAANAiQhoAAECLCGkAAAAtIqQBAAC0yP8Dyri/JNct20cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0E9Y2Ci4EdK"
      },
      "source": [
        "#③ 클러스터링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "oua-fNZg0kEJ",
        "outputId": "503df44d-0fc1-429b-97e1-36266cee52d6"
      },
      "source": [
        "clustering_flag = 0\r\n",
        "clustering_flag = int(input(\"Clustering (1 : K-menas / 2: K-shape / 3 : DBSCAN / 4 : ISODATA) :  \"))\r\n",
        "\r\n",
        "# 1 : K-menas / 2 : K-shape / 3 : DBSCAN / 4 : ISODATA(ISODATA 수정해야함)\r\n",
        "\r\n",
        "if clustering_flag == 1:\r\n",
        "\r\n",
        "  MAX_CLUSTER_SIZE = int(input(\"MAX_CLUSTER_SIZE : \"))\r\n",
        "  clustering_KMEANS(embedding_data,MAX_CLUSTER_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "elif clustering_flag == 2:\r\n",
        "  MAX_CLUSTER_SIZE = int(input(\"MAX_CLUSTER_SIZE : \"))\r\n",
        "  draw_inertia_kshape(dataset,MAX_CLUSTER_SIZE)\r\n",
        "  \r\n",
        "  N_CLUSTERS = int(input(\"N_CLUSTERS : \"))\r\n",
        "\r\n",
        "  predict = clustering_KSHAPE(dataset,n_cluster=N_CLUSTERS)\r\n",
        "  draw_vector_data(embedding_data,predict)\r\n",
        "\r\n",
        "elif clustering_flag == 3:\r\n",
        "  EPS = float(input(\"EPS : \"))\r\n",
        "  MIN_SAMPLES = int(input(\"MIN_SAMPLES : \"))\r\n",
        "\r\n",
        "  predict = clsutering_DBSCAN(embedding_data,EPS,MIN_SAMPLES)\r\n",
        "\r\n",
        "  draw_vector_data(embedding_data,predict)\r\n",
        "\r\n",
        "elif clustering_flag == 4:\r\n",
        "\r\n",
        "  predict = clustering_ISODATA(embedding_data)\r\n",
        "  draw_vector_data(embedding_data,predict)\r\n",
        "else :\r\n",
        "  pass"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-226-b49914ff373a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclustering_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclustering_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Clustering (1 : K-menas / 2: K-shape / 3 : DBSCAN / 4 : ISODATA) :  \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 1 : K-menas / 2 : K-shape / 3 : DBSCAN / 4 : ISODATA(ISODATA 수정해야함)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z14ZVXrzaHUr"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}